{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Define paths\n",
    "PROCESSED_DIR = Path(\"../data/processed\")\n",
    "\n",
    "print(f\"Processed data directory: {PROCESSED_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b459dac",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3327985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed datasets\n",
    "def load_processed_data():\n",
    "    \"\"\"Load all available processed datasets\"\"\"\n",
    "    datasets = {}\n",
    "    \n",
    "    # Try to load integrated dataset\n",
    "    integrated_file = PROCESSED_DIR / \"integrated_dataset.parquet\"\n",
    "    if integrated_file.exists():\n",
    "        try:\n",
    "            datasets['integrated'] = pd.read_parquet(integrated_file)\n",
    "            print(f\"Loaded integrated dataset: {len(datasets['integrated'])} records\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading integrated dataset: {e}\")\n",
    "    \n",
    "    # Try to load individual processed datasets\n",
    "    processed_files = list(PROCESSED_DIR.glob(\"*.parquet\"))\n",
    "    for file_path in processed_files:\n",
    "        if 'integrated' not in str(file_path):\n",
    "            try:\n",
    "                name = file_path.stem.replace('_processed', '')\n",
    "                datasets[name] = pd.read_parquet(file_path)\n",
    "                print(f\"Loaded {name} dataset: {len(datasets[name])} records\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path.name}: {e}\")\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# Load data\n",
    "data = load_processed_data()\n",
    "print(f\"\\nLoaded {len(data)} datasets: {list(data.keys())}\")\n",
    "\n",
    "# Display sample of each dataset\n",
    "for name, df in data.items():\n",
    "    print(f\"\\n{name.upper()} DATASET:\")\n",
    "    display(df.head())\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c55c9b",
   "metadata": {},
   "source": [
    "## 2. Weather Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2addd38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather data visualizations\n",
    "if 'weather' in data:\n",
    "    weather_df = data['weather']\n",
    "    \n",
    "    # Temperature over time\n",
    "    fig = px.line(weather_df, x='date', y='temperature', color='city',\n",
    "                  title='Temperature Trends by City',\n",
    "                  labels={'temperature': 'Temperature (°C)', 'date': 'Date'})\n",
    "    fig.show()\n",
    "    \n",
    "    # Temperature distribution\n",
    "    fig = px.histogram(weather_df, x='temperature', color='city',\n",
    "                       title='Temperature Distribution by City',\n",
    "                       marginal='box')\n",
    "    fig.show()\n",
    "    \n",
    "    # Weather conditions\n",
    "    weather_counts = weather_df.groupby(['city', 'weather_main']).size().reset_index(name='count')\n",
    "    fig = px.bar(weather_counts, x='city', y='count', color='weather_main',\n",
    "                 title='Weather Conditions by City',\n",
    "                 labels={'count': 'Frequency', 'weather_main': 'Weather Condition'})\n",
    "    fig.show()\n",
    "    \n",
    "    # Temperature vs Humidity scatter\n",
    "    fig = px.scatter(weather_df, x='temperature', y='humidity', color='city',\n",
    "                     title='Temperature vs Humidity',\n",
    "                     labels={'temperature': 'Temperature (°C)', 'humidity': 'Humidity (%)'})\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"Weather data not available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413d4455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather dashboard prototype\n",
    "if 'weather' in data:\n",
    "    weather_df = data['weather']\n",
    "    \n",
    "    # Create subplot figure\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Temperature Trends', 'Humidity Distribution', \n",
    "                       'Weather Conditions', 'Temperature vs Humidity'),\n",
    "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "               [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "    )\n",
    "    \n",
    "    # Temperature trends\n",
    "    for city in weather_df['city'].unique():\n",
    "        city_data = weather_df[weather_df['city'] == city]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=city_data['date'], y=city_data['temperature'], name=f'{city} Temp'),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # Humidity distribution\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=weather_df['humidity'], name='Humidity'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Weather conditions\n",
    "    weather_counts = weather_df['weather_main'].value_counts()\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=weather_counts.index, y=weather_counts.values, name='Weather Conditions'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Temperature vs Humidity\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=weather_df['temperature'], y=weather_df['humidity'], \n",
    "                  mode='markers', name='Temp vs Humidity'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(height=800, title_text=\"Weather Dashboard Prototype\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c59bd2",
   "metadata": {},
   "source": [
    "## 3. Retail Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5339e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retail data visualizations\n",
    "if 'retail' in data:\n",
    "    retail_df = data['retail']\n",
    "    \n",
    "    # Identify numeric columns for visualization\n",
    "    numeric_cols = retail_df.select_dtypes(include=['number']).columns\n",
    "    print(f\"Numeric columns available: {numeric_cols.tolist()}\")\n",
    "    \n",
    "    # Time series if date column exists\n",
    "    if 'date' in retail_df.columns and len(numeric_cols) > 0:\n",
    "        # Plot first numeric column over time\n",
    "        fig = px.line(retail_df, x='date', y=numeric_cols[0],\n",
    "                      title=f'{numeric_cols[0]} Over Time')\n",
    "        fig.show()\n",
    "    \n",
    "    # Distribution plots for numeric columns\n",
    "    for col in numeric_cols[:3]:  # First 3 numeric columns\n",
    "        fig = px.histogram(retail_df, x=col, title=f'{col} Distribution',\n",
    "                          marginal='box')\n",
    "        fig.show()\n",
    "    \n",
    "    # Correlation heatmap if multiple numeric columns\n",
    "    if len(numeric_cols) > 1:\n",
    "        corr_matrix = retail_df[numeric_cols].corr()\n",
    "        fig = px.imshow(corr_matrix, title='Correlation Matrix',\n",
    "                       labels=dict(color=\"Correlation\"))\n",
    "        fig.show()\n",
    "        \n",
    "else:\n",
    "    print(\"Retail data not available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e75551",
   "metadata": {},
   "source": [
    "## 4. Headlines Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4856aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headlines data visualizations\n",
    "if 'headlines' in data:\n",
    "    headlines_df = data['headlines']\n",
    "    \n",
    "    # Headlines over time\n",
    "    if 'date' in headlines_df.columns:\n",
    "        daily_counts = headlines_df.groupby('date').size().reset_index(name='count')\n",
    "        fig = px.line(daily_counts, x='date', y='count',\n",
    "                      title='Headlines Volume Over Time',\n",
    "                      labels={'count': 'Number of Headlines'})\n",
    "        fig.show()\n",
    "    \n",
    "    # Source distribution\n",
    "    if 'source' in headlines_df.columns:\n",
    "        source_counts = headlines_df['source'].value_counts().head(10)\n",
    "        fig = px.bar(source_counts, x=source_counts.index, y=source_counts.values,\n",
    "                     title='Top News Sources',\n",
    "                     labels={'x': 'Source', 'y': 'Number of Headlines'})\n",
    "        fig.show()\n",
    "    \n",
    "    # Title length distribution\n",
    "    if 'title_length' in headlines_df.columns:\n",
    "        fig = px.histogram(headlines_df, x='title_length',\n",
    "                          title='Headline Title Length Distribution',\n",
    "                          labels={'title_length': 'Title Length (characters)'})\n",
    "        fig.show()\n",
    "        \n",
    "else:\n",
    "    print(\"Headlines data not available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb137941",
   "metadata": {},
   "source": [
    "## 5. Integrated Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8843ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrated data visualizations\n",
    "if 'integrated' in data:\n",
    "    integrated_df = data['integrated']\n",
    "    \n",
    "    print(f\"Integrated dataset columns: {integrated_df.columns.tolist()}\")\n",
    "    \n",
    "    # Temperature vs Sales (if both exist)\n",
    "    temp_cols = [col for col in integrated_df.columns if 'temp' in col.lower()]\n",
    "    sales_cols = [col for col in integrated_df.columns if any(term in col.lower() for term in ['sales', 'revenue', 'amount'])]\n",
    "    \n",
    "    if temp_cols and sales_cols:\n",
    "        fig = px.scatter(integrated_df, x=temp_cols[0], y=sales_cols[0],\n",
    "                        title=f'{sales_cols[0]} vs {temp_cols[0]}',\n",
    "                        trendline='ols')\n",
    "        fig.show()\n",
    "    \n",
    "    # Multi-variable time series\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "    # Add temperature\n",
    "    if temp_cols:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=integrated_df['date'], y=integrated_df[temp_cols[0]], \n",
    "                      name=temp_cols[0], line=dict(color='red')),\n",
    "            secondary_y=False\n",
    "        )\n",
    "    \n",
    "    # Add sales/revenue\n",
    "    if sales_cols:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=integrated_df['date'], y=integrated_df[sales_cols[0]], \n",
    "                      name=sales_cols[0], line=dict(color='blue')),\n",
    "            secondary_y=True\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(title_text=\"Temperature vs Sales Over Time\")\n",
    "    fig.update_xaxes(title_text=\"Date\")\n",
    "    fig.update_yaxes(title_text=\"Temperature (°C)\", secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"Sales\", secondary_y=True)\n",
    "    fig.show()\n",
    "    \n",
    "    # Correlation analysis\n",
    "    numeric_cols = integrated_df.select_dtypes(include=['number']).columns\n",
    "    if len(numeric_cols) > 1:\n",
    "        corr_matrix = integrated_df[numeric_cols].corr()\n",
    "        fig = px.imshow(corr_matrix, title='Integrated Data Correlation Matrix',\n",
    "                       labels=dict(color=\"Correlation\"))\n",
    "        fig.show()\n",
    "        \n",
    "else:\n",
    "    print(\"Integrated data not available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c52025",
   "metadata": {},
   "source": [
    "## 6. Dashboard Layout Prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7844773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPI Cards Prototype\n",
    "def create_kpi_cards(data_dict):\n",
    "    \"\"\"Create KPI summary cards\"\"\"\n",
    "    kpis = {}\n",
    "    \n",
    "    for name, df in data_dict.items():\n",
    "        kpis[name] = {\n",
    "            'total_records': len(df),\n",
    "            'date_range': f\"{df['date'].min()} to {df['date'].max()}\",\n",
    "            'numeric_columns': len(df.select_dtypes(include=['number']).columns),\n",
    "            'missing_values': df.isnull().sum().sum()\n",
    "        }\n",
    "    \n",
    "    return kpis\n",
    "\n",
    "# Create KPI cards\n",
    "kpi_data = create_kpi_cards(data)\n",
    "\n",
    "# Display KPIs\n",
    "for dataset, kpis in kpi_data.items():\n",
    "    print(f\"\\n{dataset.upper()} KPIs:\")\n",
    "    for key, value in kpis.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e746cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit-style dashboard layout prototype\n",
    "def create_dashboard_layout():\n",
    "    \"\"\"Prototype dashboard layout with matplotlib/seaborn\"\"\"\n",
    "    \n",
    "    if not data:\n",
    "        print(\"No data available for dashboard\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "    fig.suptitle('ETL Dashboard Prototype', fontsize=16)\n",
    "    \n",
    "    # Row 1: KPIs\n",
    "    axes[0,0].text(0.5, 0.5, f\"Total Records\\n{sum(len(df) for df in data.values())}\", \n",
    "                   transform=axes[0,0].transAxes, ha='center', va='center', fontsize=14)\n",
    "    axes[0,0].set_title('Total Records')\n",
    "    axes[0,0].axis('off')\n",
    "    \n",
    "    axes[0,1].text(0.5, 0.5, f\"Datasets\\n{len(data)}\", \n",
    "                   transform=axes[0,1].transAxes, ha='center', va='center', fontsize=14)\n",
    "    axes[0,1].set_title('Active Datasets')\n",
    "    axes[0,1].axis('off')\n",
    "    \n",
    "    # Row 2: Weather data\n",
    "    if 'weather' in data:\n",
    "        weather_df = data['weather']\n",
    "        if 'temperature' in weather_df.columns:\n",
    "            weather_df['temperature'].hist(ax=axes[1,0], bins=20, alpha=0.7)\n",
    "            axes[1,0].set_title('Temperature Distribution')\n",
    "            axes[1,0].set_xlabel('Temperature (°C)')\n",
    "        \n",
    "        if 'weather_main' in weather_df.columns:\n",
    "            weather_counts = weather_df['weather_main'].value_counts()\n",
    "            weather_counts.plot(kind='bar', ax=axes[1,1])\n",
    "            axes[1,1].set_title('Weather Conditions')\n",
    "            axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    else:\n",
    "        axes[1,0].text(0.5, 0.5, 'Weather data\\nnot available', \n",
    "                       transform=axes[1,0].transAxes, ha='center', va='center')\n",
    "        axes[1,1].text(0.5, 0.5, 'Weather data\\nnot available', \n",
    "                       transform=axes[1,1].transAxes, ha='center', va='center')\n",
    "    \n",
    "    # Row 3: Headlines data\n",
    "    if 'headlines' in data:\n",
    "        headlines_df = data['headlines']\n",
    "        if 'source' in headlines_df.columns:\n",
    "            source_counts = headlines_df['source'].value_counts().head(5)\n",
    "            source_counts.plot(kind='bar', ax=axes[2,0])\n",
    "            axes[2,0].set_title('Top News Sources')\n",
    "            axes[2,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        if 'date' in headlines_df.columns:\n",
    "            daily_counts = headlines_df.groupby('date').size()\n",
    "            daily_counts.plot(ax=axes[2,1])\n",
    "            axes[2,1].set_title('Headlines Over Time')\n",
    "            axes[2,1].tick_params(axis='x', rotation=45)\n",
    "    else:\n",
    "        axes[2,0].text(0.5, 0.5, 'Headlines data\\nnot available', \n",
    "                       transform=axes[2,0].transAxes, ha='center', va='center')\n",
    "        axes[2,1].text(0.5, 0.5, 'Headlines data\\nnot available', \n",
    "                       transform=axes[2,1].transAxes, ha='center', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create dashboard layout\n",
    "create_dashboard_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3b6a2a",
   "metadata": {},
   "source": [
    "## 7. Interactive Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive correlation explorer\n",
    "def create_correlation_explorer(df, title):\n",
    "    \"\"\"Create interactive correlation matrix\"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    if len(numeric_cols) < 2:\n",
    "        print(f\"Not enough numeric columns in {title} for correlation analysis\")\n",
    "        return\n",
    "    \n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "    \n",
    "    fig = px.imshow(corr_matrix,\n",
    "                    title=f'{title} - Correlation Matrix',\n",
    "                    labels=dict(color=\"Correlation\"),\n",
    "                    zmin=-1, zmax=1)\n",
    "    fig.show()\n",
    "\n",
    "# Create correlation explorers for each dataset\n",
    "for name, df in data.items():\n",
    "    create_correlation_explorer(df, name.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c935e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series explorer\n",
    "def create_time_series_explorer(df, name):\n",
    "    \"\"\"Create interactive time series visualization\"\"\"\n",
    "    if 'date' not in df.columns:\n",
    "        print(f\"No date column in {name} dataset\")\n",
    "        return\n",
    "    \n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    if len(numeric_cols) == 0:\n",
    "        print(f\"No numeric columns in {name} dataset\")\n",
    "        return\n",
    "    \n",
    "    # Create subplot for multiple numeric columns\n",
    "    fig = make_subplots(rows=len(numeric_cols), cols=1, \n",
    "                        subplot_titles=[f'{col} Over Time' for col in numeric_cols],\n",
    "                        shared_xaxes=True)\n",
    "    \n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df['date'], y=df[col], name=col),\n",
    "            row=i+1, col=1\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(height=300*len(numeric_cols), title_text=f\"{name.title()} Time Series\")\n",
    "    fig.show()\n",
    "\n",
    "# Create time series explorers\n",
    "for name, df in data.items():\n",
    "    create_time_series_explorer(df, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4009568e",
   "metadata": {},
   "source": [
    "## 8. Export Visualization Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export visualization functions for dashboard\n",
    "visualization_code = '''\n",
    "# Visualization functions for Streamlit dashboard\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def create_weather_dashboard(weather_df):\n",
    "    \"\"\"Create weather dashboard visualizations\"\"\"\n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        # Temperature trends\n",
    "        fig = px.line(weather_df, x='date', y='temperature', color='city',\n",
    "                      title='Temperature Trends')\n",
    "        st.plotly_chart(fig)\n",
    "    \n",
    "    with col2:\n",
    "        # Weather conditions\n",
    "        weather_counts = weather_df['weather_main'].value_counts()\n",
    "        fig = px.bar(x=weather_counts.index, y=weather_counts.values,\n",
    "                     title='Weather Conditions')\n",
    "        st.plotly_chart(fig)\n",
    "\n",
    "def create_headlines_dashboard(headlines_df):\n",
    "    \"\"\"Create headlines dashboard visualizations\"\"\"\n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        # Headlines over time\n",
    "        daily_counts = headlines_df.groupby('date').size().reset_index(name='count')\n",
    "        fig = px.line(daily_counts, x='date', y='count',\n",
    "                      title='Headlines Volume')\n",
    "        st.plotly_chart(fig)\n",
    "    \n",
    "    with col2:\n",
    "        # Top sources\n",
    "        source_counts = headlines_df['source'].value_counts().head(10)\n",
    "        fig = px.bar(x=source_counts.index, y=source_counts.values,\n",
    "                     title='Top News Sources')\n",
    "        st.plotly_chart(fig)\n",
    "\n",
    "def create_integrated_dashboard(integrated_df):\n",
    "    \"\"\"Create integrated data dashboard visualizations\"\"\"\n",
    "    # Temperature vs Sales correlation\n",
    "    temp_cols = [col for col in integrated_df.columns if 'temp' in col.lower()]\n",
    "    sales_cols = [col for col in integrated_df.columns if any(term in col.lower() for term in ['sales', 'revenue', 'amount'])]\n",
    "    \n",
    "    if temp_cols and sales_cols:\n",
    "        fig = px.scatter(integrated_df, x=temp_cols[0], y=sales_cols[0],\n",
    "                        title=f'{sales_cols[0]} vs {temp_cols[0]}',\n",
    "                        trendline='ols')\n",
    "        st.plotly_chart(fig)\n",
    "    \n",
    "    # Correlation matrix\n",
    "    numeric_cols = integrated_df.select_dtypes(include=['number']).columns\n",
    "    if len(numeric_cols) > 1:\n",
    "        corr_matrix = integrated_df[numeric_cols].corr()\n",
    "        fig = px.imshow(corr_matrix, title='Correlation Matrix')\n",
    "        st.plotly_chart(fig)\n",
    "'''\n",
    "\n",
    "# Save visualization code\n",
    "viz_file = Path(\"../scripts/visualization_functions.py\")\n",
    "with open(viz_file, 'w') as f:\n",
    "    f.write(visualization_code)\n",
    "\n",
    "print(f\"Visualization functions exported to: {viz_file.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da4f2e1",
   "metadata": {},
   "source": [
    "## 9. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"VISUALIZATION PROTOTYPING SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"Datasets analyzed: {len(data)}\")\n",
    "for name, df in data.items():\n",
    "    print(f\"  - {name}: {len(df)} records, {len(df.columns)} columns\")\n",
    "\n",
    "print(\"\\nVISUALIZATION TYPES TESTED:\")\n",
    "print(\"✓ Line charts (time series)\")\n",
    "print(\"✓ Bar charts (categorical data)\")\n",
    "print(\"✓ Histograms (distributions)\")\n",
    "print(\"✓ Scatter plots (correlations)\")\n",
    "print(\"✓ Heatmaps (correlation matrices)\")\n",
    "print(\"✓ Interactive Plotly charts\")\n",
    "print(\"✓ Multi-panel dashboards\")\n",
    "\n",
    "print(\"\\nDASHBOARD COMPONENTS PROTOTYPED:\")\n",
    "print(\"✓ KPI summary cards\")\n",
    "print(\"✓ Weather monitoring section\")\n",
    "print(\"✓ Retail analytics section\")\n",
    "print(\"✓ News headlines section\")\n",
    "print(\"✓ Integrated analysis section\")\n",
    "\n",
    "print(\"\\nRECOMMENDATIONS FOR PRODUCTION:\")\n",
    "print(\"1. Use Plotly for interactive visualizations in Streamlit\")\n",
    "print(\"2. Implement caching for expensive computations\")\n",
    "print(\"3. Add date range filters to all time series charts\")\n",
    "print(\"4. Include data quality indicators on dashboard\")\n",
    "print(\"5. Add export functionality for charts\")\n",
    "print(\"6. Consider using themes/colors consistent with company branding\")\n",
    "print(\"7. Add tooltips and hover information to charts\")\n",
    "print(\"8. Implement responsive design for different screen sizes\")\n",
    "\n",
    "print(\"\\nNEXT STEPS:\")\n",
    "print(\"1. Integrate approved visualizations into dashboard.py\")\n",
    "print(\"2. Add user interaction features (filters, drill-downs)\")\n",
    "print(\"3. Test dashboard performance with large datasets\")\n",
    "print(\"4. Add automated chart updates when data refreshes\")\n",
    "print(\"5. Document visualization standards and guidelines\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
